{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgHaVre7uCv6"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK8hOn_8wuwX"
   },
   "outputs": [],
   "source": [
    "with open('hw4_trs.pkl', 'rb') as f:\n",
    "    trs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HIfHgU8Bw3MQ",
    "outputId": "00b1687a-1d7e-4620-ddac-220f2527e477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 16180)\n"
     ]
    }
   ],
   "source": [
    "print(trs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WC70hvzI7sqH"
   },
   "outputs": [],
   "source": [
    "padded_trs = np.zeros((500,22631))\n",
    "padded_trs[:, :16180] = trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BFVescdC6-3B",
    "outputId": "e7a1e204-f5e6-40bb-a40e-de93163639ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 22631)\n"
     ]
    }
   ],
   "source": [
    "print(padded_trs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dq7wOsc_ym2E"
   },
   "outputs": [],
   "source": [
    "with open('hw4_tes.pkl', 'rb') as f:\n",
    "    tes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PG_ZrgK9yrbF",
    "outputId": "332e8b85-2493-4467-b144-a9ee24d19879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 22631)\n"
     ]
    }
   ],
   "source": [
    "print(tes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GSVwSjPkT1fm",
    "outputId": "083038bb-1552-4670-ded0-53dc6a4efefb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 513, 45)\n"
     ]
    }
   ],
   "source": [
    "train_data=[]\n",
    "\n",
    "for i in range(500):\n",
    "    S=librosa.stft(padded_trs[i], n_fft=1024, hop_length=512)\n",
    "    train_data.append(S)\n",
    "\n",
    "train_data=np.asarray(train_data)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tPpa7TXjnRxp",
    "outputId": "d81cf575-a635-4dfc-bdb9-214b17430259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "train_data=np.abs(train_data).transpose((0,2,1))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q7QEIE0hkOvS",
    "outputId": "9cf4b0b2-9e96-4e65-a32c-9eb7bccd343a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 513, 45)\n"
     ]
    }
   ],
   "source": [
    "test_data=[]\n",
    "for i in range(200):\n",
    "    S=librosa.stft(tes[i], n_fft=1024, hop_length=512)\n",
    "    test_data.append(S)\n",
    "\n",
    "test_data=np.asarray(test_data)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ByEhXvU6nUkH",
    "outputId": "66569dcc-0c80-4379-9c70-c0a42bd0c89c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "test_data=np.abs(test_data).transpose((0,2,1))\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywVrr5WSngWm"
   },
   "outputs": [],
   "source": [
    "def generate_pairs(data):\n",
    "  l = len(data)\n",
    "  all_pos_pairs = list()\n",
    "  all_neg_pairs = list()\n",
    "  \n",
    "  for i in range(0,l,10):\n",
    "    pos_pair = list(combinations(data[i:i+10],2))\n",
    "    pos_labels = [1 for i in range(len(pos_pair))]\n",
    "    all_pos_pairs += pos_pair\n",
    "    \n",
    "    \n",
    "    temp_neg_pair = list(itertools.product(data[i:i+10], list(itertools.chain(data[i+10:l] , data[0:i]))))\n",
    "    neg_pair = random.sample(temp_neg_pair, 45)\n",
    "    all_neg_pairs += neg_pair\n",
    "  \n",
    "  pos_labels = [1 for i in range(len(all_pos_pairs))]\n",
    "  neg_labels = [0 for i in range(len(all_neg_pairs))]\n",
    "  combined_pairs = all_pos_pairs + all_neg_pairs\n",
    "  combined_labels = pos_labels + neg_labels\n",
    "  \n",
    "  temp = list(zip(combined_pairs, combined_labels))\n",
    "  random.shuffle(temp)\n",
    "  combined_pairs, combined_labels = zip(*temp)\n",
    "  return np.asarray(combined_pairs), np.asarray(combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "53UCQyhy3I2V",
    "outputId": "1f476cee-ee5f-4f7e-be59-a5da4d0ece86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2, 45, 513)\n",
      "(45, 2, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "pos_pair = np.asarray(list(combinations(train_data[0:0+10],2)))\n",
    "print(pos_pair.shape)\n",
    "\n",
    "neg_pair = list(itertools.product(train_data[0:0+10], train_data[10:500]))\n",
    "neg_pair = np.asarray(random.sample(neg_pair, 45))\n",
    "print(neg_pair.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "fcyx0NZT0g_-",
    "outputId": "592d8bcf-7b89-4ab4-8fc1-59ea37c0a710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 2, 45, 513)\n",
      "(4500,)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels = generate_pairs(train_data)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "koVmnPkk6d94",
    "outputId": "a008613c-e15f-4c5b-a2c5-0a781de5cb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "left_train_set = train_set[:,0,:,:]\n",
    "print(left_train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KjDWWq7Q6nOv",
    "outputId": "c127f26f-b522-446d-db18-254a8ae29793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "right_train_set = train_set[:,1,:,:]\n",
    "print(right_train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "pmXARPZc5Gf7",
    "outputId": "33ed411f-3cc0-4d01-945f-5b243e67a6f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 2, 45, 513)\n",
      "(1800,)\n"
     ]
    }
   ],
   "source": [
    "test_set, test_labels = generate_pairs(test_data)\n",
    "\n",
    "print(test_set.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6_mRahF26tHS",
    "outputId": "a8b21818-54fc-464f-aa14-d0a1ce808a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "left_test_set = test_set[:,0,:,:]\n",
    "print(left_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qAryDtHY6t6J",
    "outputId": "8efaef5a-76c8-40e1-d6c2-ad59945fc18d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "right_test_set = test_set[:,1,:,:]\n",
    "print(right_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6E-tD5b37UNQ"
   },
   "outputs": [],
   "source": [
    "X_left = tf.placeholder(\"float\", [None,45, 513])\n",
    "X_right = tf.placeholder(\"float\", [None,45, 513])\n",
    "\n",
    "Y = tf.placeholder(\"float\", [None])\n",
    "\n",
    "n_hidden_1 = 512\n",
    "n_hidden_2 = 512\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCVDno_k_CUf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def construct_model(X, reuse):\n",
    "    \n",
    "    GRU_stack = []\n",
    "    conv_layer_1 = tf.layers.conv1d(inputs=X, filters=32, kernel_size=2, activation = tf.nn.relu, reuse = reuse)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv_layer_1, pool_size=2, strides=2)\n",
    "    \n",
    "    \n",
    "    gru_cell_1 = tf.nn.rnn_cell.GRUCell(n_hidden_1, kernel_initializer=tf.contrib.layers.xavier_initializer(), reuse = reuse)   \n",
    "    GRU_stack.append(gru_cell_1)\n",
    "    \n",
    "    gru_cell_2 = tf.nn.rnn_cell.GRUCell(n_hidden_2, kernel_initializer=tf.contrib.layers.xavier_initializer(), reuse = reuse)\n",
    "    GRU_stack.append(gru_cell_2)\n",
    "    \n",
    "    stacked_cells = tf.nn.rnn_cell.MultiRNNCell(GRU_stack)\n",
    "    \n",
    "    gru_op, _ = tf.nn.dynamic_rnn(stacked_cells, max_pool_1, dtype = tf.float32, swap_memory = True)\n",
    "    norm_out = tf.contrib.layers.batch_norm(gru_op, is_training=True, updates_collections=None)\n",
    "    \n",
    "    drop_out_1 = tf.nn.dropout(norm_out, 0.5)\n",
    "    fc1 = tf.layers.flatten(drop_out_1)\n",
    "\n",
    "    output_layer = tf.layers.dense(inputs = fc1, \n",
    "                           units = 513, \n",
    "                           kernel_initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
    "                           activation = tf.nn.tanh,\n",
    "                           bias_initializer = tf.zeros_initializer(),\n",
    "                           reuse=reuse)\n",
    "#     print(output_layer.get_shape())\n",
    "\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "BDgGEgJkM66c",
    "outputId": "be6e13ee-ce25-4cfe-b896-deaeafdcc5f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-b064b8938e37>:5: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv1d instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-21-b064b8938e37>:6: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling1d instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-21-b064b8938e37>:9: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-21-b064b8938e37>:15: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-21-b064b8938e37>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-21-b064b8938e37>:20: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-21-b064b8938e37>:21: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-21-b064b8938e37>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "output_left = construct_model(X_left, reuse=False)\n",
    "output_right = construct_model(X_right, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "U12bVwF7XFRO",
    "outputId": "f2eb78b3-d6bd-4008-88c6-314301a5822c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n",
      "(?,)\n",
      "(?,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "dotProduct = tf.reduce_sum(tf.multiply(output_left,output_right),axis = 1 ,name = 'dotproduct')\n",
    "print(dotProduct.get_shape())\n",
    "\n",
    "yPred = tf.nn.sigmoid(dotProduct)\n",
    "print(yPred.get_shape())\n",
    "\n",
    "binarisedOutput = tf.cast(tf.math.greater(yPred,0.5), tf.int16)\n",
    "print(binarisedOutput.get_shape())\n",
    "\n",
    "\n",
    "accuracy = tf.metrics.accuracy(labels = Y, predictions = binarisedOutput)\n",
    "\n",
    "lossCalcu = tf.nn.sigmoid_cross_entropy_with_logits(labels = Y, logits = dotProduct)\n",
    "lossCalcu  = tf.reduce_sum(lossCalcu)\n",
    "step = tf.Variable(0, trainable=False)\n",
    "rate = tf.train.exponential_decay(0.001, step, 1, 0.99)\n",
    "gradOptimizer = tf.train.AdamOptimizer(learning_rate=rate)\n",
    "\n",
    "train = gradOptimizer.minimize(lossCalcu)\n",
    "# accuracy = RSquared(LastOutput,Y)\n",
    "\n",
    "initialise = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3537
    },
    "colab_type": "code",
    "id": "UoSZQCYQXVlQ",
    "outputId": "72cd1c30-0ed8-4552-a7a4-bc7c72b7f624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss= 139144.17260742188\n",
      "Accuracy on test set =  [66.77777778]\n",
      "Step 1, Loss= 86360.95776367188\n",
      "Accuracy on test set =  [66.33333333]\n",
      "Step 2, Loss= 68927.22592163086\n",
      "Accuracy on test set =  [62.55555556]\n",
      "Step 3, Loss= 67467.93090820312\n",
      "Accuracy on test set =  [66.11111111]\n",
      "Step 4, Loss= 54504.642150878906\n",
      "Accuracy on test set =  [67.83333333]\n",
      "Step 5, Loss= 39631.10614776611\n",
      "Accuracy on test set =  [65.55555556]\n",
      "Step 6, Loss= 36688.14434814453\n",
      "Accuracy on test set =  [66.05555556]\n",
      "Step 7, Loss= 31728.97315979004\n",
      "Accuracy on test set =  [66.05555556]\n",
      "Step 8, Loss= 25309.4853515625\n",
      "Accuracy on test set =  [66.88888889]\n",
      "Step 9, Loss= 25825.53832244873\n",
      "Accuracy on test set =  [65.33333333]\n",
      "Step 10, Loss= 16869.779090881348\n",
      "Accuracy on test set =  [66.44444444]\n",
      "Step 11, Loss= 13999.753005981445\n",
      "Accuracy on test set =  [68.27777778]\n",
      "Step 12, Loss= 12924.104054450989\n",
      "Accuracy on test set =  [67.11111111]\n",
      "Step 13, Loss= 14278.611179351807\n",
      "Accuracy on test set =  [66.33333333]\n",
      "Step 14, Loss= 14873.895103406161\n",
      "Accuracy on test set =  [67.61111111]\n",
      "Step 15, Loss= 9742.109941482544\n",
      "Accuracy on test set =  [68.61111111]\n",
      "Step 16, Loss= 11352.639683574438\n",
      "Accuracy on test set =  [67.55555556]\n",
      "Step 17, Loss= 8258.385559082031\n",
      "Accuracy on test set =  [68.55555556]\n",
      "Step 18, Loss= 5965.037902355194\n",
      "Accuracy on test set =  [68.05555556]\n",
      "Step 19, Loss= 5845.391760587692\n",
      "Accuracy on test set =  [68.72222222]\n",
      "Step 20, Loss= 4354.217923283577\n",
      "Accuracy on test set =  [68.]\n",
      "Step 21, Loss= 3538.744572892785\n",
      "Accuracy on test set =  [69.11111111]\n",
      "Step 22, Loss= 4029.649049770087\n",
      "Accuracy on test set =  [68.61111111]\n",
      "Step 23, Loss= 3492.3225702419877\n",
      "Accuracy on test set =  [68.55555556]\n",
      "Step 24, Loss= 3305.29120978876\n",
      "Accuracy on test set =  [68.27777778]\n",
      "Step 25, Loss= 2939.914399385588\n",
      "Accuracy on test set =  [68.27777778]\n",
      "Step 26, Loss= 3000.559553036178\n",
      "Accuracy on test set =  [67.72222222]\n",
      "Step 27, Loss= 2824.3148202449083\n",
      "Accuracy on test set =  [70.16666667]\n",
      "Step 28, Loss= 2928.179708869313\n",
      "Accuracy on test set =  [69.]\n",
      "Step 29, Loss= 2702.9453449478797\n",
      "Accuracy on test set =  [69.16666667]\n",
      "Step 30, Loss= 2155.2328137940494\n",
      "Accuracy on test set =  [69.22222222]\n",
      "Step 31, Loss= 2555.1613278985023\n",
      "Accuracy on test set =  [71.77777778]\n",
      "Step 32, Loss= 1877.807954990145\n",
      "Accuracy on test set =  [70.38888889]\n",
      "Step 33, Loss= 1536.7230175813165\n",
      "Accuracy on test set =  [70.11111111]\n",
      "Step 34, Loss= 1254.8537262658524\n",
      "Accuracy on test set =  [70.]\n",
      "Step 35, Loss= 1241.3675419804358\n",
      "Accuracy on test set =  [71.94444444]\n",
      "Step 36, Loss= 1531.904618371229\n",
      "Accuracy on test set =  [70.83333333]\n",
      "Step 37, Loss= 1370.540956122597\n",
      "Accuracy on test set =  [70.61111111]\n",
      "Step 38, Loss= 1480.5816956050694\n",
      "Accuracy on test set =  [70.11111111]\n",
      "Step 39, Loss= 1418.2801134279382\n",
      "Accuracy on test set =  [70.27777778]\n",
      "Step 40, Loss= 1521.4498153765453\n",
      "Accuracy on test set =  [73.44444444]\n",
      "Step 41, Loss= 1421.6483785444834\n",
      "Accuracy on test set =  [71.22222222]\n",
      "Step 42, Loss= 1122.5526458096679\n",
      "Accuracy on test set =  [72.05555556]\n",
      "Step 43, Loss= 928.3706347262205\n",
      "Accuracy on test set =  [70.94444444]\n",
      "Step 44, Loss= 821.0189134781249\n",
      "Accuracy on test set =  [71.44444444]\n",
      "Step 45, Loss= 1190.526008915881\n",
      "Accuracy on test set =  [72.94444444]\n",
      "Step 46, Loss= 800.3711610042787\n",
      "Accuracy on test set =  [72.]\n",
      "Step 47, Loss= 998.2024307529009\n",
      "Accuracy on test set =  [71.11111111]\n",
      "Step 48, Loss= 658.2697402624713\n",
      "Accuracy on test set =  [72.11111111]\n",
      "Step 49, Loss= 598.0497101578018\n",
      "Accuracy on test set =  [72.72222222]\n",
      "Step 50, Loss= 562.0007656074911\n",
      "Accuracy on test set =  [72.66666667]\n",
      "Step 51, Loss= 331.4135608271137\n",
      "Accuracy on test set =  [72.55555556]\n",
      "Step 52, Loss= 340.0018737088751\n",
      "Accuracy on test set =  [72.44444444]\n",
      "Step 53, Loss= 622.9939993166347\n",
      "Accuracy on test set =  [73.77777778]\n",
      "Step 54, Loss= 235.1708706446625\n",
      "Accuracy on test set =  [73.11111111]\n",
      "Step 55, Loss= 325.13657643362905\n",
      "Accuracy on test set =  [72.33333333]\n",
      "Step 56, Loss= 442.7170117227241\n",
      "Accuracy on test set =  [73.33333333]\n",
      "Step 57, Loss= 354.1545371312175\n",
      "Accuracy on test set =  [73.72222222]\n",
      "Step 58, Loss= 211.9771126262153\n",
      "Accuracy on test set =  [75.38888889]\n",
      "Step 59, Loss= 515.704634547263\n",
      "Accuracy on test set =  [73.72222222]\n",
      "Step 60, Loss= 332.8305971675851\n",
      "Accuracy on test set =  [75.05555556]\n",
      "Step 61, Loss= 409.8808561589566\n",
      "Accuracy on test set =  [75.]\n",
      "Step 62, Loss= 655.8349820427663\n",
      "Accuracy on test set =  [74.5]\n",
      "Step 63, Loss= 455.18641653250626\n",
      "Accuracy on test set =  [73.83333333]\n",
      "Step 64, Loss= 541.1927664454679\n",
      "Accuracy on test set =  [74.61111111]\n",
      "Step 65, Loss= 529.6265242711645\n",
      "Accuracy on test set =  [73.72222222]\n",
      "Step 66, Loss= 332.41501230155563\n",
      "Accuracy on test set =  [72.5]\n",
      "Step 67, Loss= 746.7893351218822\n",
      "Accuracy on test set =  [73.16666667]\n",
      "Step 68, Loss= 794.7022960938074\n",
      "Accuracy on test set =  [74.94444444]\n",
      "Step 69, Loss= 444.33902391425033\n",
      "Accuracy on test set =  [74.66666667]\n",
      "Step 70, Loss= 699.0499431417277\n",
      "Accuracy on test set =  [75.]\n",
      "Step 71, Loss= 668.6414609668939\n",
      "Accuracy on test set =  [72.66666667]\n",
      "Step 72, Loss= 790.9919150277752\n",
      "Accuracy on test set =  [72.55555556]\n",
      "Step 73, Loss= 719.7867330661788\n",
      "Accuracy on test set =  [72.83333333]\n",
      "Step 74, Loss= 350.40387340797895\n",
      "Accuracy on test set =  [72.11111111]\n",
      "Step 75, Loss= 749.5910470686904\n",
      "Accuracy on test set =  [72.72222222]\n",
      "Step 76, Loss= 691.7365191653091\n",
      "Accuracy on test set =  [72.5]\n",
      "Step 77, Loss= 393.99932159783816\n",
      "Accuracy on test set =  [72.77777778]\n",
      "Step 78, Loss= 386.70400966136094\n",
      "Accuracy on test set =  [73.11111111]\n",
      "Step 79, Loss= 600.8168756538574\n",
      "Accuracy on test set =  [72.77777778]\n",
      "Step 80, Loss= 383.3233180458642\n",
      "Accuracy on test set =  [73.66666667]\n",
      "Step 81, Loss= 569.8953426338428\n",
      "Accuracy on test set =  [73.16666667]\n",
      "Step 82, Loss= 416.9308458839018\n",
      "Accuracy on test set =  [73.88888889]\n",
      "Step 83, Loss= 490.61751937124535\n",
      "Accuracy on test set =  [75.72222222]\n",
      "Step 84, Loss= 648.6918343391279\n",
      "Accuracy on test set =  [74.83333333]\n",
      "Step 85, Loss= 351.3519216298657\n",
      "Accuracy on test set =  [73.72222222]\n",
      "Step 86, Loss= 473.85462566644094\n",
      "Accuracy on test set =  [75.27777778]\n",
      "Step 87, Loss= 432.27749850977875\n",
      "Accuracy on test set =  [75.94444444]\n",
      "Step 88, Loss= 565.2295800986244\n",
      "Accuracy on test set =  [74.11111111]\n",
      "Step 89, Loss= 624.856464677586\n",
      "Accuracy on test set =  [73.61111111]\n",
      "Step 90, Loss= 565.3638841859864\n",
      "Accuracy on test set =  [74.16666667]\n",
      "Step 91, Loss= 431.33039497232437\n",
      "Accuracy on test set =  [75.05555556]\n",
      "Step 92, Loss= 376.0837652207998\n",
      "Accuracy on test set =  [74.38888889]\n",
      "Step 93, Loss= 484.299744234439\n",
      "Accuracy on test set =  [73.77777778]\n",
      "Step 94, Loss= 556.9045069430672\n",
      "Accuracy on test set =  [74.38888889]\n",
      "Step 95, Loss= 519.4435736866137\n",
      "Accuracy on test set =  [73.11111111]\n",
      "Step 96, Loss= 342.68666707330016\n",
      "Accuracy on test set =  [74.55555556]\n",
      "Step 97, Loss= 365.6318000723809\n",
      "Accuracy on test set =  [74.38888889]\n",
      "Step 98, Loss= 320.49214632235316\n",
      "Accuracy on test set =  [76.11111111]\n",
      "Step 99, Loss= 447.4886050360383\n",
      "Accuracy on test set =  [74.61111111]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(initialise)\n",
    "for epoch in range(100):\n",
    "  loss = []\n",
    "  for i in range(0, int(len(train_set)/batch_size)):\n",
    "    r = random.randint(0, len(train_set)-batch_size)\n",
    "\n",
    "#     xbatchLeft = left_train_set[i*batch_size:(i+1)*batch_size,:,:]\n",
    "#     xbatchRight = right_train_set[i*batch_size:(i+1)*batch_size,:,:]\n",
    "#     yBatch = train_labels[i*batch_size:(i+1)*batch_size]\n",
    "    \n",
    "    xbatchLeft = left_train_set[r:r+batch_size,:,:]\n",
    "    xbatchRight = right_train_set[r:r+batch_size,:,:]\n",
    "    yBatch = train_labels[r:r+batch_size]\n",
    "    \n",
    "    sess.run(train,feed_dict ={X_left: xbatchLeft,\n",
    "                               X_right: xbatchRight,Y:yBatch,})\n",
    "    loss += sess.run([lossCalcu], feed_dict ={X_left: xbatchLeft,\n",
    "                                              X_right: xbatchRight,Y:yBatch})  \n",
    "\n",
    "  print(\"Step \" + str(epoch) + \", Loss= \" + str(sum(loss)))\n",
    "  predictedytest = binarisedOutput.eval(feed_dict ={X_left: left_test_set,\n",
    "                                      X_right: right_test_set,Y:test_labels})\n",
    "  totalequal = sum(predictedytest==test_labels) \n",
    "  accuracy =totalequal/ test_labels.shape\n",
    "  accuracy =accuracy*100\n",
    "  print(\"Accuracy on test set = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "coEEx99AxXA-"
   },
   "outputs": [],
   "source": [
    "predictedytest = binarisedOutput.eval(feed_dict ={X_left: left_test_set,\n",
    "                                      X_right: right_test_set,Y:test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pom77Tq61AOT",
    "outputId": "4feff677-26ea-44d8-c225-f17310f83074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74.55555556]\n"
     ]
    }
   ],
   "source": [
    "totalequal = sum(predictedytest==test_labels) \n",
    "accuracy =totalequal/ test_labels.shape\n",
    "accuracy =accuracy*100\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
